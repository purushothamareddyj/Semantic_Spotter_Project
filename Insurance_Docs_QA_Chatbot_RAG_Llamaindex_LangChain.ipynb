{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "\n",
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "import nest_asyncio\n",
    "from diskcache import Cache\n",
    "\n",
    "import getpass\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key: Please Note this is a demo version, only openai is currently supported. Input is hidden\n"
     ]
    }
   ],
   "source": [
    "# Apply nested asyncio to allow for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Ask user for OpenAI API key and set it\n",
    "print(\"Enter your OpenAI API key: Please Note this is a demo version, only openai is currently supported. Input is hidden\")\n",
    "api_key = getpass.getpass()\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Initialize a persistent Chroma database client with the specified path\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma.db\")\n",
    "\n",
    "# Define the path to the directory containing PDF documents to be processed\n",
    "pdf_dir_path = \"./dataset_folder\"\n",
    "\n",
    "# Set the language model and embedding model to be used for processing\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "# Initialize a cache to store results, with a specified cache directory\n",
    "cache = Cache(\"./cache\")\n",
    "#Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(pdf_dir_path, storage_context):\n",
    "    \"\"\"Builds a vector store index from PDF documents.\n",
    "\n",
    "    Args:\n",
    "        pdf_dir_path (str): The path to the directory containing PDF documents to be indexed.\n",
    "        storage_context (StorageContext): The context for storing the vector index.\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex: The created vector store index containing the processed documents.\n",
    "    \"\"\"  \n",
    "    # Load documents from the specified directory\n",
    "    docs = SimpleDirectoryReader(pdf_dir_path).load_data()\n",
    "    \n",
    "    # Create an ingestion pipeline with specified transformations\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[\n",
    "            # Split documents into sentences with specified chunk size and overlap\n",
    "            SentenceSplitter(chunk_size=2048, chunk_overlap=0),\n",
    "            # Extract titles from the documents\n",
    "            TitleExtractor(),\n",
    "            # Use OpenAI's embedding model for text embedding\n",
    "            OpenAIEmbedding(model_name=\"text-embedding-ada-002\"),\n",
    "            #HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Run the pipeline on the loaded documents to create nodes\n",
    "    nodes = pipeline.run(documents=docs)\n",
    "    \n",
    "    # Create a vector store index from the nodes and the provided storage context\n",
    "    index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)\n",
    "\n",
    "    return index  # Return the created index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_retrieval(query, index):\n",
    "    \"\"\"Retrieves data based on the provided query from the specified index.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string used to search for relevant data.\n",
    "        index (VectorStoreIndex): The index from which to retrieve data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of results matching the query.\n",
    "    \"\"\"\n",
    "    # Convert the index into a retriever object for querying\n",
    "    retriever = index.as_retriever()\n",
    "    \n",
    "    # Retrieve results based on the provided query\n",
    "    results = retriever.retrieve(query)\n",
    "    \n",
    "    return results  # Return the retrieved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index():\n",
    "    \"\"\"Creates and saves a vector store index from PDF documents.\n",
    "\n",
    "    This function attempts to create a new Chroma collection for storing the index.\n",
    "    If the collection already exists, it retrieves the existing collection.\n",
    "    It then builds the index from the documents in the specified directory and saves it.\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex or None: The created vector store index if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    print(\"Creating and saving the index\")\n",
    "    \n",
    "    # Attempt to create a new Chroma collection for storing the index\n",
    "    try:\n",
    "        chroma_collection = chroma_client.create_collection(name=\"Insurance_Doc_RAG_LlamaIndex_LangChain\")\n",
    "    except Exception as e:\n",
    "        # If the collection already exists, retrieve the existing collection\n",
    "        print(f\"Collection already exists: {e}\")\n",
    "        chroma_collection = chroma_client.get_collection(name=\"Insurance_Doc_RAG_LlamaIndex_LangChain\")\n",
    "\n",
    "    # Initialize a vector store with the Chroma collection\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    \n",
    "    # Create a storage context using the default settings and the vector store\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    # Attempt to build the index from the documents and save it\n",
    "    try:\n",
    "        index = build_index(pdf_dir_path, storage_context)\n",
    "        print(\"Index created and saved\")\n",
    "        return index  # Return the created index\n",
    "    except Exception as e:\n",
    "        # If an error occurs during index building, print the error and return None\n",
    "        print(f\"Error while building the index: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index():\n",
    "    \"\"\"Loads the vector store index from a Chroma collection.\n",
    "\n",
    "    This function attempts to load a vector store index from a specified Chroma collection.\n",
    "    If the collection exists, it retrieves the collection and constructs a vector store index.\n",
    "    If the collection does not exist or an error occurs, it returns None.\n",
    "\n",
    "    Returns:\n",
    "        VectorStoreIndex or None: The loaded vector store index if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    # Attempt to retrieve the specified collection from the Chroma database\n",
    "    try:\n",
    "        chroma_collection = chroma_client.get_collection(name=\"Insurance_Doc_RAG_LlamaIndex_LangChain\")\n",
    "    except Exception as e:\n",
    "        # Print an error message if the collection cannot be loaded\n",
    "        print(f\"Error loading the collection: {e}\")\n",
    "        return None\n",
    "\n",
    "    print(\"Loading the index\")\n",
    "    # Initialize a ChromaVectorStore with the retrieved collection\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    # Create a storage context using default settings and the vector store\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    try:\n",
    "        # Attempt to create a VectorStoreIndex from the vector store and storage context\n",
    "        index = VectorStoreIndex.from_vector_store(\n",
    "            vector_store=vector_store,\n",
    "            storage_context=storage_context\n",
    "        )\n",
    "        return index  # Return the successfully loaded index\n",
    "    except Exception as e:\n",
    "        # Print an error message if the index cannot be loaded\n",
    "        print(f\"Error while loading the index: {e}\")\n",
    "        return None  # Return None if the index cannot be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading the collection: Collection Insurance_Doc_RAG_LlamaIndex_LangChain does not exist.\n",
      "Creating and saving the index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created and saved\n",
      "Index is ready\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load the existing vector store index\n",
    "index = load_index()\n",
    "\n",
    "# If loading the index fails, attempt to create and save a new index\n",
    "if index is None:\n",
    "    index = save_index()\n",
    "\n",
    "# Check if the index is successfully loaded or created\n",
    "if index:\n",
    "    print(\"Index is ready\")  # Indicate that the index is ready for use\n",
    "else:\n",
    "    print(\"Failed to create or load the index\")  # Indicate failure in loading or creating the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(query):\n",
    "    \"\"\"Retrieves documents based on the provided query, utilizing a cache for efficiency.\n",
    "\n",
    "    This function first checks if the results for the given query are already cached. \n",
    "    If cached results are found, they are returned immediately. \n",
    "    If not, it retrieves the results from the index and caches them for future use.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string used to search for relevant documents.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of results matching the query.\n",
    "    \"\"\"\n",
    "    # Check if the results for the query are already in the cache\n",
    "    if cache.get(query) is not None:\n",
    "        extracted_texts = [result.node.text for result in cache.get(query)]\n",
    "        return extracted_texts\n",
    "        #return cache.get(query)  # Return cached results if available\n",
    "    \n",
    "    # Retrieve results from the index if not cached\n",
    "    results = data_retrieval(query, index)\n",
    "    \n",
    "    # Store the retrieved results in the cache with a specified expiration time\n",
    "    cache.set(query, results, expire=600)\n",
    "\n",
    "    extracted_texts = [result.node.text for result in results]\n",
    "    return extracted_texts  # Return the retrieved results\n",
    "\n",
    "# Uncomment the following line to test the function with a sample query\n",
    "# res = retrieve_docs(\"what is Waiting Period and Exclusions?\")\n",
    "# print(res)  # Uncomment to print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please Note - The following piece of code is not required to run the application and is used for internal understanding, alternate\n",
    "# prototyping ways and testing/debugging purposes. This code is not required to run this application which the code used above/below has superseded. \n",
    "\n",
    "\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# doc_tool = create_retriever_tool(\n",
    "#     retrive_docs,\n",
    "#     \"Search_docs\",\n",
    "#     \"Search and return the relevant policy document data.\",\n",
    "# )\n",
    "\n",
    "# from langchain_core.tools import tool\n",
    "# from langchain.tools import Tool\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.memory import ConversationBufferMemory\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain.agents import initialize_agent, AgentType\n",
    "# from langchain.utilities import SerpAPIWrapper \n",
    "\n",
    "# from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # search_tool = Tool(\n",
    "# #     name=\"Internet_Search\",\n",
    "# #     func=SerpAPIWrapper(serpapi_api_key=\"663d549846fac3c10e2b7d0dfeed509b0923c171084ecf2b8b4574bef5b3683a\").run,\n",
    "# #     description=\"Use this tool to search the internet for general information.\"\n",
    "# # )\n",
    "\n",
    "# # docs_tool = Tool(\n",
    "# #     name=\"Cache and Document Search\",\n",
    "# #     func=retrive_docs,\n",
    "# #     description=\"Use this tool to answer questions about policy documents.\"\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "# You are a question answering expert. The user will ask you a question/query. Answer the question to the best of your ability.\n",
    "# You have access to the following tools:\n",
    "\n",
    "# {tools}\n",
    "\n",
    "# Use the following format to interact with tools:\n",
    "# Thought: What you are thinking.\n",
    "# Action: tool_name(\"input\")\n",
    "# Observation: The result from the tool.\n",
    "\n",
    "# Always use the Search_docs tool first to find answers in insurance documents. If you can't find a satisfactory answer, use the Internet_Search tool.\n",
    "\n",
    "# Available tools: {tool_names}\n",
    "\n",
    "# Current chat history:\n",
    "# {chat_history}\n",
    "\n",
    "# Agent Scratchpad:\n",
    "# {agent_scratchpad}\n",
    "\n",
    "# Intermediate Steps:\n",
    "# {intermediate_steps}\n",
    "\n",
    "# Input: {input}\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "# #prompt = PromptTemplate.from_template(prompt_template, template_format=\"jinja2\")\n",
    "# # memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# # tools = [doc_tool, search_tool]\n",
    "# # llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# # agent = initialize_agent(tools = tools, \n",
    "# #     llm = llm, \n",
    "# #     prompt=custom_prompt, \n",
    "# #     agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "# #     verbose=True, \n",
    "# #     memory=memory)\n",
    "\n",
    "\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# langgraph_agent_executor = create_react_agent(model, tools)\n",
    "# message_history = messages[\"messages\"]\n",
    "\n",
    "# new_query = \"What is dental work?\"\n",
    "\n",
    "# messages = langgraph_agent_executor.invoke(\n",
    "#     {\"messages\": message_history + [(\"human\", new_query)]}\n",
    "# )\n",
    "# {\n",
    "#     \"input\": new_query,\n",
    "#     \"output\": messages[\"messages\"][-1].content,\n",
    "# }\n",
    "\n",
    "# #%pip install langchain-openai\n",
    "\n",
    "# from langchain_openai import OpenAI\n",
    "# from langchain.agents import AgentExecutor, create_react_agent\n",
    "# from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "# model = OpenAI(name='gpt-4o-mini',temperature=0)\n",
    "# tools = [doc_tool, search_tool]\n",
    "\n",
    "# agent = create_react_agent(model, tools, prompt_template)\n",
    "\n",
    "\n",
    "# agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, memory=memory, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Initialize the language model with the specified model and API key\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "@tool\n",
    "def doc_search_tool(query: str): \n",
    "    \"\"\"Searches the documents for relevant information.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search within the documents.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of relevant document excerpts matching the query.\n",
    "    \"\"\"\n",
    "    return retrieve_docs(query)\n",
    "\n",
    "@tool\n",
    "def internet_search_tool(query: str):\n",
    "    \"\"\"Searches the internet for general information.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query string to search on the internet.\n",
    "\n",
    "    Returns:\n",
    "        str: The result of the internet search.\n",
    "    \"\"\"\n",
    "    return SerpAPIWrapper(serpapi_api_key=\"663d549846fac3c10e2b7d0dfeed509b0923c171084ecf2b8b4574bef5b3683a\").run(query)\n",
    "\n",
    "# List of tools available for the agent to use\n",
    "tools = [doc_search_tool, internet_search_tool]\n",
    "\n",
    "# Example query to demonstrate the agent's functionality\n",
    "query = \"What is the procedure to claim the insurance?\"\n",
    "\n",
    "# Define the prompt template for the chat agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a question answering expert. The user will ask you a question/query. Answer the question to the best of your ability\n",
    "         Only use the Search_docs tool first to find answers in insurance documents. If you can't find a satisfactory answer, use the Internet_Search tool.\n",
    "         \"\"\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the agent using the model, tools, and prompt\n",
    "agent = create_tool_calling_agent(model, tools, prompt)\n",
    "\n",
    "# Initialize the agent executor with the created agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "\n",
    "# Uncomment the following line to invoke the agent with the example query\n",
    "# agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a thread ID to the configuration for saving the conversation.\n",
    "# This ensures that each conversation is saved and context is retained.\n",
    "\n",
    "config = {\"configurable\" : {\"thread_id\" : \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Insurance Documentation Chatbot. Please enter your query. Type 'exit' to quit.\n",
      "User:  what is Waiting Period and Exclusions?\n",
      "Searching... Please wait!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chatbot:  ### Waiting Period\n",
      "The **Waiting Period** refers to a specified duration during which no benefits will be paid if a covered event occurs. For example, in the context of the Accelerated Critical Illness Benefit, there is a **90 Days Waiting Period**. This means that if a Scheme Member is diagnosed with any applicable listed Critical Illness or undergoes surgery within 90 days from the commencement of the coverage term, no benefits will be payable. However, if the Critical Illness is a result of an accident (such as Major Head Trauma), this waiting period may not apply.\n",
      "\n",
      "### Exclusions\n",
      "**Exclusions** are specific conditions or circumstances under which the insurance policy will not pay benefits. Key exclusions include:\n",
      "\n",
      "1. **Suicide Exclusion**: \n",
      "   - For employer-employee groups, the sum assured will be payable to the nominee in case of death due to suicide.\n",
      "   - For non-employer-employee schemes, if a Scheme Member dies due to suicide within 12 months from joining or reviving the policy, the nominee will receive at least 80% of the total premiums paid or the available surrender value, whichever is higher.\n",
      "\n",
      "2. **Permanent Exclusions for Accelerated Critical Illness Benefit**: \n",
      "   - Claims will not be paid for conditions caused by non-medically necessary treatments, substance abuse, war, nuclear disasters, intentional self-inflicted injuries, and more.\n",
      "   - Specific exclusions include claims related to critical illnesses occurring within 90 days of coverage commencement or revival, and any pre-existing conditions.\n",
      "\n",
      "3. **Accidental Death Benefit Exclusions**: \n",
      "   - No benefit will be payable if death occurs more than 180 days after the accident or if the death is caused by self-inflicted injuries, substance abuse, or participation in hazardous activities.\n",
      "\n",
      "These exclusions and waiting periods are important for policyholders to understand to avoid surprises when making claims.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User:  is Alzheimer's Disease covered under critical illness benefits?\n",
      "Searching... Please wait!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chatbot:  Yes, **Alzheimer's Disease** is covered under critical illness benefits. It is classified as a covered critical illness in the insurance policy documentation. The policy defines Alzheimer's Disease as a deterioration or loss of intellectual capacity confirmed by clinical evaluation and imaging tests, resulting in significant reduction in mental and social functioning that requires continuous supervision of the insured individual. \n",
      "\n",
      "However, it's important to note that alcohol-related brain damage is specifically excluded from coverage.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "User:  what is alcohol-related brain damage?\n",
      "Searching... Please wait!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Chatbot:  **Alcohol-related brain damage (ARBD)** is a brain disorder caused by excessive and prolonged consumption of alcohol. It encompasses the cognitive impairments and behavioral changes that result from regular heavy drinking or binge-drinking over several years.\n",
      "\n",
      "Key features of alcohol-related brain damage include:\n",
      "\n",
      "- **Cognitive Impairment**: This can manifest as problems with thinking, memory, planning, and overall cognitive function.\n",
      "- **Behavioral Changes**: Individuals may experience changes in behavior and coordination due to the effects of alcohol on the brain.\n",
      "- **Severity**: While severe damage typically occurs after years of heavy drinking, negative effects on brain function can begin to appear even after consuming alcohol above recommended limits for a shorter duration.\n",
      "\n",
      "Overall, ARBD is an umbrella term that describes the various types of brain damage that can result from long-term alcohol abuse, and it often includes conditions such as Wernicke-Korsakoff syndrome, which is associated with thiamine deficiency due to alcohol consumption.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Thanks for using Insurance Documentation Chatbot. Have a great day!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Welcome message for the user and instructions on how to exit the chatbot\n",
    "print(\"Welcome to Insurance Documentation Chatbot. Please enter your query. Type 'exit' to quit.\")\n",
    "\n",
    "# Initialize an empty list to store the conversation history\n",
    "message_history = []\n",
    "\n",
    "# Continuously prompt the user for input until they type 'exit'\n",
    "query = input(\"User: \")\n",
    "while query.lower() != \"exit\":\n",
    "    # Display the user's query\n",
    "    print(\"User: \", query)\n",
    "    print(\"Searching... Please wait!\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Combine the message history with the current query for context\n",
    "    combined_messages = message_history + [(\"human\", query)]\n",
    "    \n",
    "    # Invoke the agent executor with the combined messages to get a response\n",
    "    response = agent_executor.invoke({\"input\": combined_messages})\n",
    "    \n",
    "    # Create a dictionary to store the input and output of the current interaction\n",
    "    messages = {\n",
    "        \"input\": query,\n",
    "        \"output\": response['output'],\n",
    "    }\n",
    "    \n",
    "    # Display the chatbot's response\n",
    "    print(\"Chatbot: \", response['output'])\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Append the current interaction to the message history\n",
    "    message_history.append(messages)\n",
    "    \n",
    "    # Prompt the user for the next query\n",
    "    query = input(\"User: \")\n",
    "\n",
    "# Thank the user for using the chatbot when they exit\n",
    "if 'exit' in query.lower():\n",
    "    print(\"Thanks for using Insurance Documentation Chatbot. Have a great day!\")\n",
    "    print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
